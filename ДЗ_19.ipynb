{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaya-686/AI/blob/main/%D0%94%D0%97_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1\n",
        "Напишіть функцію, яка повертає список фраз з тексту, які відповідають певному шоблону. При необхідності можете добавити власні параметри.\n",
        "\n",
        "Протестуйте функцію на якомусь тексті."
      ],
      "metadata": {
        "id": "D56Rwjf4EXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/text_for_homework.txt', 'r') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "7mvAXibVca57"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "q8yhlHx4dLVY"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "49fAfAFjgVfI",
        "outputId": "11f34597-e531-45cb-f430-0239d2bbf246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "8KbF_8pFdLIr",
        "outputId": "fe994745-a668-483c-9c36-8d4d14e5c90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def validate_regex_format(regex):\n",
        "    format_regex = r'^\\{(<[A-Z]+.*?>)+\\}$'\n",
        "\n",
        "    if re.match(format_regex, regex):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "N37wSFUonAud"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phrases(text, regex, tag_name):\n",
        "\n",
        "  if not validate_regex_format(regex):\n",
        "    raise ValueError(\"Incorrect regex\")\n",
        "\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  tags = nltk.pos_tag(words)\n",
        "\n",
        "  grammar = f'{tag_name}: {regex}'\n",
        "\n",
        "  chunk_parser = nltk.RegexpParser(grammar)\n",
        "\n",
        "  tree = chunk_parser.parse(tags)\n",
        "\n",
        "  phrases = []\n",
        "\n",
        "  for subtree in tree.subtrees():\n",
        "    if subtree.label() == tag_name:\n",
        "      phrase = ' '.join(word for word, tag in subtree.leaves())\n",
        "      phrases.append((subtree.label(), phrase))\n",
        "\n",
        "  return phrases"
      ],
      "metadata": {
        "id": "G4Stff_zFQjv"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  phrases = get_phrases(text, '{<V.*><NN.*>}', 'V+NN')\n",
        "except Exception as e:\n",
        "  print(\"Message: \", e)\n"
      ],
      "metadata": {
        "id": "Ho9TtuH5f97v"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases"
      ],
      "metadata": {
        "id": "BybRm05kjL8K",
        "outputId": "9d216d03-ccca-4012-9aa8-bb3001e3c304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('V+NN', 'replace nets'),\n",
              " ('V+NN', 'snapped Atuik'),\n",
              " ('V+NN', 'aching sob'),\n",
              " ('V+NN', 'striking bone'),\n",
              " ('V+NN', 'decorated mantel'),\n",
              " ('V+NN', 'holding torches'),\n",
              " ('V+NN', 'burning bright'),\n",
              " ('V+NN', 'housed dozens'),\n",
              " ('V+NN', 'carved chair')]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    }
  ]
}